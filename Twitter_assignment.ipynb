{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajniyadavashish/Twitter_assignment/blob/main/Twitter_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Twitter Assignment - ASHISH YADAV"
      ],
      "metadata": {
        "id": "Q-nKu3CL7KFW"
      },
      "id": "Q-nKu3CL7KFW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WdjgVigVKFGr",
      "metadata": {
        "id": "WdjgVigVKFGr"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CpIJy4yDKGAN",
      "metadata": {
        "id": "CpIJy4yDKGAN"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/project_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3058bf3a",
      "metadata": {
        "id": "3058bf3a",
        "outputId": "9bf0c317-f388-44d9-916a-bff9bf0cfee2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/tweepy/tweepy.git 'C:\\Users\\TeamA\\AppData\\Local\\Temp\\pip-req-build-vc43hi9c'\n",
            "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/tweepy/tweepy.git 'C:\\Users\\TeamA\\AppData\\Local\\Temp\\pip-req-build-vc43hi9c'\n",
            "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tweepy/tweepy.git\n",
            "  Cloning https://github.com/tweepy/tweepy.git to c:\\users\\teama\\appdata\\local\\temp\\pip-req-build-vc43hi9c\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/tweepy/tweepy.git\n",
        "!pip3 install -U textblob\n",
        "!python -m textblob.download_corpora\n",
        "import tweepy\n",
        "import webbrowser\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import logging\n",
        "from logging.handlers import RotatingFileHandler\n",
        "from sys import getsizeof\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage-1\n",
        "Your program should prompt the user to input the keyword.\n",
        "You're going to write tweet JSON object per LINE in the log file. Each line can then be parsed individually.\n",
        "After successfully storing data in log files, your program should print following statistics in the console after termination\n",
        "\n",
        "Time taken to run the program\n",
        "\n",
        "Average size (in bytes) of a tweet JSON\n",
        "\n",
        "Number of log files created to store data\n",
        "\n",
        "Average number of records in a log file\n",
        "\n",
        "Average size (in KB) of a log file"
      ],
      "metadata": {
        "id": "FU7R84yo7sOa"
      },
      "id": "FU7R84yo7sOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca0853c",
      "metadata": {
        "id": "fca0853c"
      },
      "outputs": [],
      "source": [
        "# enter your api keys\n",
        "consumer_key = \"enter keys\"\n",
        "consumer_secret = \"enter keys\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c085fae1",
      "metadata": {
        "id": "c085fae1"
      },
      "outputs": [],
      "source": [
        "callback_uri = 'oob' # https://cfe.sh/twitter/callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a60c90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9a60c90",
        "outputId": "4da88629-d30e-413f-a407-6e4c6db4a977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://api.twitter.com/oauth/authorize?oauth_token=_m0DvAAAAAABWjOsAAABfbeQrr8\n"
          ]
        }
      ],
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret, callback_uri)\n",
        "redirect_url = auth.get_authorization_url()\n",
        "print(redirect_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1d40f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b1d40f8",
        "outputId": "b4a0dcd8-eb3b-4747-af4e-35a01ed0f403"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "webbrowser.open(redirect_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1077e0ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1077e0ed",
        "outputId": "3ebf2a30-0d22-4210-b27c-2440d43b5992"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "What's the pin value?  1232812\n"
          ]
        }
      ],
      "source": [
        "user_pin_input = input(\"What's the pin value? \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cede2593",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cede2593",
        "outputId": "1c6fb56d-a969-4e6b-c082-d9c8fb2e62c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1232812'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_pin_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445665f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445665f2",
        "outputId": "1bacea4c-28d4-4cf3-92fe-b7404c502041"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('1300687822505103360-xCfdbd82Xt5DzA6gOvqBQhYpnboGzJ',\n",
              " '8up0HdKPIvg5Gww5kSr4MEBdEUnXb2btkgn8jwqBVULBB')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auth.get_access_token(user_pin_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622861f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "622861f1",
        "outputId": "30fcf193-c260-40ec-9c63-4279e5ce5bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1300687822505103360-xCfdbd82Xt5DzA6gOvqBQhYpnboGzJ 8up0HdKPIvg5Gww5kSr4MEBdEUnXb2btkgn8jwqBVULBB\n"
          ]
        }
      ],
      "source": [
        "print(auth.access_token, auth.access_token_secret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f349ee9",
      "metadata": {
        "id": "7f349ee9"
      },
      "outputs": [],
      "source": [
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc6be72-a016-4a64-a062-dad8e3ab6d5d",
      "metadata": {
        "id": "5bc6be72-a016-4a64-a062-dad8e3ab6d5d",
        "outputId": "7edf1b22-7c33-47f3-fb96-13422a89882b"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter a keyword to search covid-19\n"
          ]
        }
      ],
      "source": [
        "query = input(\"Enter a keyword to search\") #enter the keyword to search about"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ADd53_I--EFE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADd53_I--EFE",
        "outputId": "d5debd23-3a42-49f1-cf94-539b6c5194d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Rate limit reached. Sleeping for: 652\n",
            "Rate limit reached. Sleeping for: 806\n",
            "Rate limit reached. Sleeping for: 810\n",
            "Rate limit reached. Sleeping for: 809\n"
          ]
        }
      ],
      "source": [
        "#set the number of max tweets to analyse\n",
        "#using only 10k tweets since scraping 100k tweets takes 8hrs\n",
        "max_tweets=10000\n",
        "geo='38.8950368,-77.0365427,250km' # washington dc geocode \n",
        "searched_tweets = [status._json for status in tweepy.Cursor(api.search_tweets,q=query,lang='en',geocode = geo).items(max_tweets)]\n",
        "json_strings = [json.dumps(json_obj) for json_obj in searched_tweets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KZB2WP07E5qa",
      "metadata": {
        "id": "KZB2WP07E5qa",
        "outputId": "9982588d-ca0a-403f-c3f0-58437afad330"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(json_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171c398f-7e47-471f-acc9-0c836cec594a",
      "metadata": {
        "id": "171c398f-7e47-471f-acc9-0c836cec594a",
        "outputId": "799239ce-9548-4dfb-8be8-812ab0813d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3154.4146\n"
          ]
        }
      ],
      "source": [
        "# finding the size of a single tweet in kb\n",
        "tweetsize=0\n",
        "avg_tweetsize=0\n",
        "no_of_tweet=len(json_strings)\n",
        "for i in json_strings:\n",
        "    tweetsize+=getsizeof(i)\n",
        "\n",
        "avg_tweetsize=tweetsize/no_of_tweet\n",
        "print(avg_tweetsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f85f468-def3-47a6-81b1-b7df57d3f8b8",
      "metadata": {
        "id": "9f85f468-def3-47a6-81b1-b7df57d3f8b8",
        "outputId": "e399f28e-bd9a-4f3f-f6c7-8ef1922d2aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TeamA\\Desktop\\Twitter_Project\\extracted\n"
          ]
        }
      ],
      "source": [
        "# changing the dirctory\n",
        "%cd C:/Users/TeamA/Desktop/Twitter_Project/extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e953307c-4058-4fbf-a986-11158ba078ff",
      "metadata": {
        "id": "e953307c-4058-4fbf-a986-11158ba078ff"
      },
      "outputs": [],
      "source": [
        "# Storing the data and splitting the files (Max file size is 1MB (Juptyter notebook limitation))\n",
        "\n",
        "logger = logging.getLogger('my_logger')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "handler = RotatingFileHandler('my_log', maxBytes=1000000, backupCount=100)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "for i in range(len(json_strings)):\n",
        "    logger.info(json_strings[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19368dbb-3f6d-4dc0-9325-661762b917a9",
      "metadata": {
        "id": "19368dbb-3f6d-4dc0-9325-661762b917a9"
      },
      "outputs": [],
      "source": [
        "#finding the number of tweets per file\n",
        "def tweet_count(filename):\n",
        "\n",
        "    file = open(filename)\n",
        "    Counter = 0\n",
        "\n",
        "    # Reading from file\n",
        "    Content = file.read()\n",
        "    CoList = Content.split(\"\\n\")\n",
        "\n",
        "    for i in CoList:\n",
        "        if i:\n",
        "            Counter += 1\n",
        "\n",
        "    return Counter # returns number of records per file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9846c06f-e0c3-41b9-8406-ccb4381d3b5e",
      "metadata": {
        "id": "9846c06f-e0c3-41b9-8406-ccb4381d3b5e"
      },
      "outputs": [],
      "source": [
        "\n",
        "directory_path = 'C:/Users/TeamA/Desktop/Twitter_Project/extracted'\n",
        "No_of_files = len(os.listdir(directory_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff93839e-40f7-49c7-99ca-3258b47e064d",
      "metadata": {
        "id": "ff93839e-40f7-49c7-99ca-3258b47e064d",
        "outputId": "e11e8edb-192e-441e-ebab-31e4ff615583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of file is 125903 bytes\n",
            "Size of file is 995097 bytes\n",
            "Size of file is 999792 bytes\n",
            "Size of file is 998182 bytes\n",
            "Size of file is 997063 bytes\n",
            "Size of file is 998956 bytes\n",
            "Size of file is 999541 bytes\n",
            "Size of file is 999224 bytes\n",
            "Size of file is 998707 bytes\n",
            "Size of file is 998854 bytes\n",
            "Size of file is 998683 bytes\n",
            "Size of file is 997771 bytes\n",
            "Size of file is 999461 bytes\n",
            "Size of file is 999484 bytes\n",
            "Size of file is 997045 bytes\n",
            "Size of file is 997313 bytes\n",
            "Size of file is 999535 bytes\n",
            "Size of file is 998569 bytes\n",
            "Size of file is 999370 bytes\n",
            "Size of file is 997667 bytes\n",
            "Size of file is 997322 bytes\n",
            "Size of file is 999757 bytes\n",
            "Size of file is 997578 bytes\n",
            "Size of file is 997809 bytes\n",
            "Size of file is 997773 bytes\n",
            "Size of file is 998494 bytes\n",
            "Size of file is 999668 bytes\n",
            "Size of file is 994983 bytes\n",
            "Size of file is 998048 bytes\n",
            "Size of file is 998126 bytes\n",
            "Size of file is 999097 bytes\n",
            "Size of file is 999274 bytes\n"
          ]
        }
      ],
      "source": [
        "#finding the file size\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "for f in files:\n",
        "    tweet_count(f)\n",
        "    file_size = os.path.getsize(f)\n",
        "    print('Size of file is', file_size, 'bytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d216319-d9da-4a82-8fe6-300658a07d99",
      "metadata": {
        "id": "3d216319-d9da-4a82-8fe6-300658a07d99"
      },
      "outputs": [],
      "source": [
        "totaltweet =0\n",
        "total_file_size=0\n",
        "for f in files:\n",
        "    totaltweet+=tweet_count(f)\n",
        "    file_size = os.path.getsize(f)\n",
        "    total_file_size+=file_size\n",
        "    \n",
        "avgtweetcnt=totaltweet/No_of_files\n",
        "avg_file_size=total_file_size/No_of_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21566c4e-f6b7-4069-943a-68b6a8f49a6a",
      "metadata": {
        "id": "21566c4e-f6b7-4069-943a-68b6a8f49a6a",
        "outputId": "05630d4e-18f2-47c4-da22-673fb82a38a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average size (in bytes) of a tweet JSON :  3154.4146\n",
            "Number of log files created to store data :  32\n",
            "Average number of records in a log file : 312.5\n",
            "Average size (in KB) of a log file : 971.0670625\n"
          ]
        }
      ],
      "source": [
        "print('Average size (in bytes) of a tweet JSON : ',avg_tweetsize)\n",
        "print('Number of log files created to store data : ',No_of_files)\n",
        "print('Average number of records in a log file :',avgtweetcnt)\n",
        "print('Average size (in KB) of a log file :',avg_file_size*0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage - 2\n",
        "You're going to write a new JSON object per LINE in the log file. Each line can then be parsed individually.\n",
        "After successfully storing data in log files, your program should print following statistics in the console after termination\n",
        "\n",
        "Time taken to run the program\n",
        "\n",
        "Average size (in bytes) of a new JSON\n",
        "\n",
        "Minimum and maximum size of new JSON objects\n",
        "\n",
        "Number of log files created to store data\n",
        "\n",
        "Average number of records in a log file\n",
        "\n",
        "Average size (in KB) of a log file\n",
        "\n",
        "Count of URLs removed"
      ],
      "metadata": {
        "id": "eHWv5HSt79ai"
      },
      "id": "eHWv5HSt79ai"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0f082e-e773-408d-bf12-6c380d986f9b",
      "metadata": {
        "id": "1e0f082e-e773-408d-bf12-6c380d986f9b"
      },
      "outputs": [],
      "source": [
        "#reading the log file\n",
        "import pandas as pd\n",
        "with open(\"my_log\") as fh:\n",
        "    tweets = [json.loads(line) for line in fh if line]\n",
        "\n",
        "df = pd.DataFrame(tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8beeee05-631e-434c-9bc8-028c0dbff652",
      "metadata": {
        "id": "8beeee05-631e-434c-9bc8-028c0dbff652",
        "outputId": "4081d65c-b199-4b3c-a276-65fa82acacb6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>truncated</th>\n",
              "      <th>entities</th>\n",
              "      <th>metadata</th>\n",
              "      <th>source</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_status_id_str</th>\n",
              "      <th>...</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_id_str</th>\n",
              "      <th>quoted_status</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>favorited</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>lang</th>\n",
              "      <th>extended_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wed Dec 08 04:02:15 +0000 2021</td>\n",
              "      <td>1468430698138812421</td>\n",
              "      <td>1468430698138812421</td>\n",
              "      <td>“So, I do have a test today actually!” \\n\\nOur...</td>\n",
              "      <td>True</td>\n",
              "      <td>{'hashtags': [{'text': 'Princeton', 'indices':...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>1.468403e+18</td>\n",
              "      <td>1468402649263390727</td>\n",
              "      <td>{'created_at': 'Wed Dec 08 02:10:47 +0000 2021...</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wed Dec 08 04:02:00 +0000 2021</td>\n",
              "      <td>1468430637774245898</td>\n",
              "      <td>1468430637774245898</td>\n",
              "      <td>@laurenboebert @RepThomasMassie Even before CO...</td>\n",
              "      <td>True</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.468411e+18</td>\n",
              "      <td>1468411381653323777</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at                   id               id_str  \\\n",
              "0  Wed Dec 08 04:02:15 +0000 2021  1468430698138812421  1468430698138812421   \n",
              "1  Wed Dec 08 04:02:00 +0000 2021  1468430637774245898  1468430637774245898   \n",
              "\n",
              "                                                text  truncated  \\\n",
              "0  “So, I do have a test today actually!” \\n\\nOur...       True   \n",
              "1  @laurenboebert @RepThomasMassie Even before CO...       True   \n",
              "\n",
              "                                            entities  \\\n",
              "0  {'hashtags': [{'text': 'Princeton', 'indices':...   \n",
              "1  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
              "\n",
              "                                            metadata  \\\n",
              "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
              "\n",
              "                                              source  in_reply_to_status_id  \\\n",
              "0  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
              "1  <a href=\"http://twitter.com/download/android\" ...           1.468411e+18   \n",
              "\n",
              "  in_reply_to_status_id_str  ...  quoted_status_id quoted_status_id_str  \\\n",
              "0                      None  ...      1.468403e+18  1468402649263390727   \n",
              "1       1468411381653323777  ...               NaN                  NaN   \n",
              "\n",
              "                                       quoted_status retweet_count  \\\n",
              "0  {'created_at': 'Wed Dec 08 02:10:47 +0000 2021...             3   \n",
              "1                                                NaN             0   \n",
              "\n",
              "  favorite_count favorited retweeted possibly_sensitive  lang  \\\n",
              "0              8     False     False              False    en   \n",
              "1              2     False     False                NaN    en   \n",
              "\n",
              "   extended_entities  \n",
              "0                NaN  \n",
              "1                NaN  \n",
              "\n",
              "[2 rows x 29 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce41f33a-ef15-4817-ab97-e62b5e5f60ec",
      "metadata": {
        "id": "ce41f33a-ef15-4817-ab97-e62b5e5f60ec",
        "outputId": "9e3a0d3f-529a-4f80-f0cd-b2527879b085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39 entries, 0 to 38\n",
            "Data columns (total 29 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   created_at                 39 non-null     object \n",
            " 1   id                         39 non-null     int64  \n",
            " 2   id_str                     39 non-null     object \n",
            " 3   text                       39 non-null     object \n",
            " 4   truncated                  39 non-null     bool   \n",
            " 5   entities                   39 non-null     object \n",
            " 6   metadata                   39 non-null     object \n",
            " 7   source                     39 non-null     object \n",
            " 8   in_reply_to_status_id      11 non-null     float64\n",
            " 9   in_reply_to_status_id_str  11 non-null     object \n",
            " 10  in_reply_to_user_id        11 non-null     float64\n",
            " 11  in_reply_to_user_id_str    11 non-null     object \n",
            " 12  in_reply_to_screen_name    11 non-null     object \n",
            " 13  user                       39 non-null     object \n",
            " 14  geo                        0 non-null      object \n",
            " 15  coordinates                0 non-null      object \n",
            " 16  place                      0 non-null      object \n",
            " 17  contributors               0 non-null      object \n",
            " 18  is_quote_status            39 non-null     bool   \n",
            " 19  quoted_status_id           3 non-null      float64\n",
            " 20  quoted_status_id_str       3 non-null      object \n",
            " 21  quoted_status              3 non-null      object \n",
            " 22  retweet_count              39 non-null     int64  \n",
            " 23  favorite_count             39 non-null     int64  \n",
            " 24  favorited                  39 non-null     bool   \n",
            " 25  retweeted                  39 non-null     bool   \n",
            " 26  possibly_sensitive         32 non-null     object \n",
            " 27  lang                       39 non-null     object \n",
            " 28  extended_entities          1 non-null      object \n",
            "dtypes: bool(4), float64(3), int64(3), object(19)\n",
            "memory usage: 7.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40c1f069-bb2d-4b6b-9c2e-afe421f88b34",
      "metadata": {
        "id": "40c1f069-bb2d-4b6b-9c2e-afe421f88b34"
      },
      "outputs": [],
      "source": [
        "# Emoji_removal \n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398f4841-4a34-4341-b732-e827d2d49d49",
      "metadata": {
        "id": "398f4841-4a34-4341-b732-e827d2d49d49"
      },
      "outputs": [],
      "source": [
        "#stop word removal\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "def stopwordrev(text):\n",
        "    filtered_sentence = remove_stopwords(text)\n",
        "    return(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71d3097-3d86-4785-9c73-637bc3ed19ab",
      "metadata": {
        "id": "d71d3097-3d86-4785-9c73-637bc3ed19ab"
      },
      "outputs": [],
      "source": [
        "#processing the Raw Tweet\n",
        "import re\n",
        "import string\n",
        "def clean_text(text):\n",
        "    \"\"\"Make text lowercase, \n",
        "       remove text in angle brackets,\n",
        "       remove \\n,\n",
        "       remove punctuation and \n",
        "       remove words containing numbers.\"\"\"\n",
        "    # lower case\n",
        "    text = str(text).lower() \n",
        "    \n",
        "    # remove text in angle brackets\n",
        "    text = re.sub('<.*?>+', '', text).strip()\n",
        "    \n",
        "    # remove punctuation\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text).strip()\n",
        "    \n",
        "    #remove newline character\n",
        "    text = re.sub('\\n', ' ', text).strip()\n",
        "    \n",
        "    # remove words containing numbers\n",
        "    text = re.sub('\\w*\\d\\w*', '', text).strip()\n",
        "    \n",
        "    text = remove_emoji(text)\n",
        "    text = stopwordrev(text)\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f92c9f-03cc-483a-85f6-5ff8858a4474",
      "metadata": {
        "id": "86f92c9f-03cc-483a-85f6-5ff8858a4474"
      },
      "outputs": [],
      "source": [
        "df['tidytweet'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe3f77f-a5e5-47ae-ad68-6c2f13c6420e",
      "metadata": {
        "id": "9fe3f77f-a5e5-47ae-ad68-6c2f13c6420e",
        "outputId": "11724643-0908-4353-c724-7224f5dc175b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'“so test today actually” absolute star firstyear reporter princeton isolation d…'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tidytweet'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45fb3009-0da5-4ec6-ac5d-6f9b9ae330c9",
      "metadata": {
        "id": "45fb3009-0da5-4ec6-ac5d-6f9b9ae330c9"
      },
      "outputs": [],
      "source": [
        "#tokenization\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def cleaner(string):\n",
        "    \n",
        "    # Generate list of tokens\n",
        "    doc = nlp(string)\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    # Remove tokens that are not alphabetic \n",
        "    a_lemmas = [lemma for lemma in lemmas if lemma.isalpha() \n",
        "                 or lemma == '-PRON-'] \n",
        "    # Print string after text cleaning\n",
        "    return a_lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18ea000-a12e-4811-ae01-4965bfdd8f2f",
      "metadata": {
        "id": "a18ea000-a12e-4811-ae01-4965bfdd8f2f"
      },
      "outputs": [],
      "source": [
        "df['tokenizedTweet']=df['tidytweet'].apply(cleaner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f711f0-c941-4c04-93de-bc2b3f7bce94",
      "metadata": {
        "id": "96f711f0-c941-4c04-93de-bc2b3f7bce94",
        "outputId": "611aae8f-587e-4183-fcba-eb587bc1b401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [so, test, today, actually, absolute, star, fi...\n",
              "1    [laurenboebert, repthomasmassie, epidemic, kil...\n",
              "2    [researcher, discover, biomarker, aid, early, ...\n",
              "3    [plantbase, vaccine, show, high, efficacy, covid]\n",
              "4    [father, fouryearold, autistic, boy, tell, ing...\n",
              "Name: tokenizedTweet, dtype: object"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tokenizedTweet'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68cb6b42-17b1-414d-91fc-05887ab29882",
      "metadata": {
        "id": "68cb6b42-17b1-414d-91fc-05887ab29882"
      },
      "outputs": [],
      "source": [
        "# finding the list of mentions in the tweet\n",
        "def mentions(text):\n",
        "    regex=re.compile(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)\")\n",
        "    result = regex.findall(text)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed7d49f-313e-4737-b1f5-f814486098ca",
      "metadata": {
        "id": "6ed7d49f-313e-4737-b1f5-f814486098ca"
      },
      "outputs": [],
      "source": [
        "# finding the list of hashtags in the tweet\n",
        "def hashtags(text):\n",
        "    regex=re.compile(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))#([A-Za-z]+[A-Za-z0-9]+)\")\n",
        "    result = regex.findall(text)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6441024e-dc0f-4283-a997-43b3ef074d1b",
      "metadata": {
        "id": "6441024e-dc0f-4283-a997-43b3ef074d1b"
      },
      "outputs": [],
      "source": [
        "df['listMentions']=df['text'].apply(mentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1ee634-9fff-401c-ac11-8eca7203d545",
      "metadata": {
        "id": "bd1ee634-9fff-401c-ac11-8eca7203d545"
      },
      "outputs": [],
      "source": [
        "df['listHashtags']=df['text'].apply(hashtags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b5d51c5-0811-4e27-9fb3-3e379ed403a3",
      "metadata": {
        "id": "2b5d51c5-0811-4e27-9fb3-3e379ed403a3"
      },
      "outputs": [],
      "source": [
        "df['tweetId']=df['id']\n",
        "df['rawTweet']=df['text']\n",
        "df['countRetweets']=df['retweet_count']\n",
        "df['placeName']=df['place']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4af9b85f-6067-4063-b8d9-1988b82b64c5",
      "metadata": {
        "id": "4af9b85f-6067-4063-b8d9-1988b82b64c5"
      },
      "outputs": [],
      "source": [
        "df_cleaned=df[['tweetId','rawTweet','tidytweet','tokenizedTweet','listMentions','listHashtags','countRetweets','placeName']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda25570-ecfa-4386-a8ee-eaff91e58eb6",
      "metadata": {
        "id": "eda25570-ecfa-4386-a8ee-eaff91e58eb6",
        "outputId": "05ba8679-aaf3-4f9e-840c-53b5ec5b656f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetId</th>\n",
              "      <th>rawTweet</th>\n",
              "      <th>tidytweet</th>\n",
              "      <th>tokenizedTweet</th>\n",
              "      <th>listMentions</th>\n",
              "      <th>listHashtags</th>\n",
              "      <th>countRetweets</th>\n",
              "      <th>placeName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1468430698138812421</td>\n",
              "      <td>“So, I do have a test today actually!” \\n\\nOur...</td>\n",
              "      <td>“so test today actually” absolute star firstye...</td>\n",
              "      <td>[so, test, today, actually, absolute, star, fi...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Princeton]</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1468430637774245898</td>\n",
              "      <td>@laurenboebert @RepThomasMassie Even before CO...</td>\n",
              "      <td>laurenboebert repthomasmassie epidemic killing...</td>\n",
              "      <td>[laurenboebert, repthomasmassie, epidemic, kil...</td>\n",
              "      <td>[laurenboebert, RepThomasMassie]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1468430284118966273</td>\n",
              "      <td>Researchers discover biomarker that could aid ...</td>\n",
              "      <td>researchers discover biomarker aid early detec...</td>\n",
              "      <td>[researcher, discover, biomarker, aid, early, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1468430278842585090</td>\n",
              "      <td>Plant-based vaccine shows high efficacy agains...</td>\n",
              "      <td>plantbased vaccine shows high efficacy covid</td>\n",
              "      <td>[plantbase, vaccine, show, high, efficacy, covid]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1468430259833880580</td>\n",
              "      <td>The father of a four-year-old autistic boy tol...</td>\n",
              "      <td>father fouryearold autistic boy told ingraham ...</td>\n",
              "      <td>[father, fouryearold, autistic, boy, tell, ing...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               tweetId                                           rawTweet  \\\n",
              "0  1468430698138812421  “So, I do have a test today actually!” \\n\\nOur...   \n",
              "1  1468430637774245898  @laurenboebert @RepThomasMassie Even before CO...   \n",
              "2  1468430284118966273  Researchers discover biomarker that could aid ...   \n",
              "3  1468430278842585090  Plant-based vaccine shows high efficacy agains...   \n",
              "4  1468430259833880580  The father of a four-year-old autistic boy tol...   \n",
              "\n",
              "                                           tidytweet  \\\n",
              "0  “so test today actually” absolute star firstye...   \n",
              "1  laurenboebert repthomasmassie epidemic killing...   \n",
              "2  researchers discover biomarker aid early detec...   \n",
              "3       plantbased vaccine shows high efficacy covid   \n",
              "4  father fouryearold autistic boy told ingraham ...   \n",
              "\n",
              "                                      tokenizedTweet  \\\n",
              "0  [so, test, today, actually, absolute, star, fi...   \n",
              "1  [laurenboebert, repthomasmassie, epidemic, kil...   \n",
              "2  [researcher, discover, biomarker, aid, early, ...   \n",
              "3  [plantbase, vaccine, show, high, efficacy, covid]   \n",
              "4  [father, fouryearold, autistic, boy, tell, ing...   \n",
              "\n",
              "                       listMentions listHashtags  countRetweets placeName  \n",
              "0                                []  [Princeton]              3      None  \n",
              "1  [laurenboebert, RepThomasMassie]           []              0      None  \n",
              "2                                []           []              0      None  \n",
              "3                                []           []              0      None  \n",
              "4                                []           []              0      None  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d430f732-cd79-4893-a53f-ffb479b5986f",
      "metadata": {
        "id": "d430f732-cd79-4893-a53f-ffb479b5986f",
        "outputId": "aa7b61ab-ae16-4176-ed65-500648e89123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39 entries, 0 to 38\n",
            "Data columns (total 8 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   tweetId         39 non-null     int64 \n",
            " 1   rawTweet        39 non-null     object\n",
            " 2   tidytweet       39 non-null     object\n",
            " 3   tokenizedTweet  39 non-null     object\n",
            " 4   listMentions    39 non-null     object\n",
            " 5   listHashtags    39 non-null     object\n",
            " 6   countRetweets   39 non-null     int64 \n",
            " 7   placeName       0 non-null      object\n",
            "dtypes: int64(2), object(6)\n",
            "memory usage: 2.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df_cleaned.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8a5fee-3f8d-4177-b9d1-105d0658e06f",
      "metadata": {
        "id": "ef8a5fee-3f8d-4177-b9d1-105d0658e06f"
      },
      "outputs": [],
      "source": [
        "# storing the cleaned records in json format\n",
        "d = df_cleaned.to_dict(orient='records')\n",
        "j = json.dumps(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b34ad30-74f3-4443-9fb3-ffcfed2d8bed",
      "metadata": {
        "id": "7b34ad30-74f3-4443-9fb3-ffcfed2d8bed"
      },
      "outputs": [],
      "source": [
        "cleaned_json_list=[json.dumps(json_obj) for json_obj in d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ff6e2d-ebe4-4a3c-88b2-9f61833000a3",
      "metadata": {
        "id": "a6ff6e2d-ebe4-4a3c-88b2-9f61833000a3",
        "outputId": "4963a0de-97ff-470d-e9a1-69c8c6d04a70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"tweetId\": 1468430698138812421, \"rawTweet\": \"\\\\u201cSo, I do have a test today actually!\\\\u201d \\\\n\\\\nOur absolute star first-year reporter in a #Princeton COVID-19 isolation d\\\\u2026 https://t.co/NYVge3f9Nr\", \"tidytweet\": \"\\\\u201cso test today actually\\\\u201d absolute star firstyear reporter princeton isolation d\\\\u2026\", \"tokenizedTweet\": [\"so\", \"test\", \"today\", \"actually\", \"absolute\", \"star\", \"firstyear\", \"reporter\", \"princeton\", \"isolation\", \"d\"], \"listMentions\": [], \"listHashtags\": [\"Princeton\"], \"countRetweets\": 3, \"placeName\": null}'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_json_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d449e0-d8ac-4332-8969-1f112f70840a",
      "metadata": {
        "id": "17d449e0-d8ac-4332-8969-1f112f70840a",
        "outputId": "66a28752-04ae-4803-db84-2fd725b7e7ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TeamA\\Desktop\\Twitter_Project\\cleansed\n"
          ]
        }
      ],
      "source": [
        "%cd C:/Users/TeamA/Desktop/Twitter_Project/cleansed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cdd3295-de02-443d-bff2-0b928322a419",
      "metadata": {
        "id": "1cdd3295-de02-443d-bff2-0b928322a419"
      },
      "outputs": [],
      "source": [
        "# splitting and saving the cleaned data in log files\n",
        "count_row = df.shape[0]\n",
        "logger = logging.getLogger('my_logger_cleaned')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "handler = RotatingFileHandler('my_log_cleaned', maxBytes=1000000, backupCount=100)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "for i in range(count_row):\n",
        "    logger.info(cleaned_json_list[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a72e16ef-0152-4499-849c-7c99b7ec0214",
      "metadata": {
        "id": "a72e16ef-0152-4499-849c-7c99b7ec0214"
      },
      "outputs": [],
      "source": [
        "#changing the directory\n",
        "directory_path = 'C:/Users/TeamA/Desktop/Twitter_Project/cleansed'\n",
        "No_of_files = len(os.listdir(directory_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a159fa4-bfba-4cf6-b8f9-1494f6d895d8",
      "metadata": {
        "id": "4a159fa4-bfba-4cf6-b8f9-1494f6d895d8",
        "outputId": "524af027-45ea-499e-f851-5be8d74295f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of file my_log_cleaned is 18697 bytes\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(directory_path)\n",
        "\n",
        "for f in files:\n",
        "    tweet_count(f)\n",
        "    file_size = os.path.getsize(f)\n",
        "    print('Size of file', f,'is', file_size, 'bytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be35544f-e39f-4706-9820-7ee19dc221dc",
      "metadata": {
        "id": "be35544f-e39f-4706-9820-7ee19dc221dc"
      },
      "outputs": [],
      "source": [
        "totaltweet =0\n",
        "total_file_size=0\n",
        "for f in files:\n",
        "    totaltweet+=tweet_count(f)\n",
        "    file_size = os.path.getsize(f)\n",
        "    total_file_size+=file_size\n",
        "    \n",
        "avgtweetcnt=totaltweet/No_of_files\n",
        "avg_file_size=total_file_size/No_of_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a4e1f5-003c-40a4-9f0c-b46cad13ea07",
      "metadata": {
        "id": "04a4e1f5-003c-40a4-9f0c-b46cad13ea07",
        "outputId": "29ac8a77-aaa5-43a5-b959-7c1c23d945f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average size (in bytes) of cleaned tweet JSON :  3154.4146\n",
            "Number of new log files created to store data :  1\n",
            "Average number of records in cleaned log file : 39.0\n",
            "Average size (in KB) of a log file : 18.697\n"
          ]
        }
      ],
      "source": [
        "print('Average size (in bytes) of cleaned tweet JSON : ',avg_tweetsize)\n",
        "print('Number of new log files created to store data : ',No_of_files)\n",
        "print('Average number of records in cleaned log file :',avgtweetcnt)\n",
        "print('Average size (in KB) of a log file :',avg_file_size*0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage-3\n",
        "\n",
        "Problem A - Generate Word count"
      ],
      "metadata": {
        "id": "9HAAeiqQ8OeD"
      },
      "id": "9HAAeiqQ8OeD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e440e2-1323-4ce5-8ae5-355f9c5c202b",
      "metadata": {
        "id": "78e440e2-1323-4ce5-8ae5-355f9c5c202b"
      },
      "outputs": [],
      "source": [
        "#finding the word count and saving it to csv\n",
        "path='C:/Users/TeamA/Desktop/Twitter_Project/wordcounts/'\n",
        "def cleansed_csv(file):\n",
        "    with open(file+'') as fh:\n",
        "        tweets = [json.loads(line) for line in fh if line]\n",
        "    df = pd.DataFrame(tweets)\n",
        "    wordcount = df['tidytweet'].str.split(expand=True).stack().value_counts().reset_index()\n",
        "    wordcount.columns = ['Word', 'Frequency']\n",
        "    return wordcount.to_csv(path+'_'+file+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a493f01-f9e6-464a-ab05-2cd644dfae6a",
      "metadata": {
        "id": "7a493f01-f9e6-464a-ab05-2cd644dfae6a"
      },
      "outputs": [],
      "source": [
        "directory_path = 'C:/Users/TeamA/Desktop/Twitter_Project/cleansed'\n",
        "for f in files:\n",
        "    cleansed_csv(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem C - Sentiment Analysis and its distribution"
      ],
      "metadata": {
        "id": "jWDTsOgP8Zrq"
      },
      "id": "jWDTsOgP8Zrq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a530cf-5825-48e8-a44e-d5a87d48a9dd",
      "metadata": {
        "id": "82a530cf-5825-48e8-a44e-d5a87d48a9dd",
        "outputId": "09a534f4-ba1f-4cad-d20b-d7e3cd4467e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\TeamA\\AppData\\Roaming\\nltk_data...\n"
          ]
        }
      ],
      "source": [
        "#sentiment analysis of the tweets\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "twtsnt = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a63259-b10d-456c-8aed-2c76f4eb33c9",
      "metadata": {
        "id": "16a63259-b10d-456c-8aed-2c76f4eb33c9",
        "outputId": "17c257d2-ced9-4cdd-ff2a-16f1a9ed6a72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TeamA\\AppData\\Local\\Temp/ipykernel_17584/2130666309.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['score'] = df_cleaned['tidytweet'].apply(lambda review: twtsnt.polarity_scores(review))\n"
          ]
        }
      ],
      "source": [
        "df_cleaned['score'] = df_cleaned['tidytweet'].apply(lambda review: twtsnt.polarity_scores(review))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a88a70b-fbce-434f-b37d-fbebac98be33",
      "metadata": {
        "id": "3a88a70b-fbce-434f-b37d-fbebac98be33"
      },
      "outputs": [],
      "source": [
        "df_scores=df_cleaned[['tidytweet','score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "048a047c-8703-4ff3-a884-82bc19b5d801",
      "metadata": {
        "id": "048a047c-8703-4ff3-a884-82bc19b5d801",
        "outputId": "c59470bf-a69d-41c5-ff4e-962c40e09576"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TeamA\\AppData\\Local\\Temp/ipykernel_17584/3060321930.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_scores['compound']  = df_scores['score'].apply(lambda score_dict: score_dict['compound'])\n"
          ]
        }
      ],
      "source": [
        "df_scores['compound']  = df_scores['score'].apply(lambda score_dict: score_dict['compound'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb1cc8b-d5e4-4f5b-bfc5-c48d509f1917",
      "metadata": {
        "id": "efb1cc8b-d5e4-4f5b-bfc5-c48d509f1917",
        "outputId": "4a68bc89-ffe3-4621-cbfa-fa24f0dcd681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TeamA\\AppData\\Local\\Temp/ipykernel_17584/2716455355.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_scores['compound'] = df_scores['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n"
          ]
        }
      ],
      "source": [
        "df_scores['compound'] = df_scores['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b24fc7a-c06e-48e4-a89b-87618f3e0747",
      "metadata": {
        "id": "3b24fc7a-c06e-48e4-a89b-87618f3e0747",
        "outputId": "a4cc4037-f076-4e36-c5b3-fc7e91c0f0d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tidytweet</th>\n",
              "      <th>score</th>\n",
              "      <th>compound</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“so test today actually” absolute star firstye...</td>\n",
              "      <td>{'neg': 0.213, 'neu': 0.787, 'pos': 0.0, 'comp...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>laurenboebert repthomasmassie epidemic killing...</td>\n",
              "      <td>{'neg': 0.493, 'neu': 0.507, 'pos': 0.0, 'comp...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>researchers discover biomarker aid early detec...</td>\n",
              "      <td>{'neg': 0.208, 'neu': 0.792, 'pos': 0.0, 'comp...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>plantbased vaccine shows high efficacy covid</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>father fouryearold autistic boy told ingraham ...</td>\n",
              "      <td>{'neg': 0.214, 'neu': 0.786, 'pos': 0.0, 'comp...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tidytweet  \\\n",
              "0  “so test today actually” absolute star firstye...   \n",
              "1  laurenboebert repthomasmassie epidemic killing...   \n",
              "2  researchers discover biomarker aid early detec...   \n",
              "3       plantbased vaccine shows high efficacy covid   \n",
              "4  father fouryearold autistic boy told ingraham ...   \n",
              "\n",
              "                                               score compound  \n",
              "0  {'neg': 0.213, 'neu': 0.787, 'pos': 0.0, 'comp...      neg  \n",
              "1  {'neg': 0.493, 'neu': 0.507, 'pos': 0.0, 'comp...      neg  \n",
              "2  {'neg': 0.208, 'neu': 0.792, 'pos': 0.0, 'comp...      neg  \n",
              "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      pos  \n",
              "4  {'neg': 0.214, 'neu': 0.786, 'pos': 0.0, 'comp...      neg  "
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_scores.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6fe4b2c-1db6-4ce7-993f-8c32c82531aa",
      "metadata": {
        "id": "b6fe4b2c-1db6-4ce7-993f-8c32c82531aa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Twitter_assignment",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}